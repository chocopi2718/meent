{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2,3'\n",
    "\n",
    "\n",
    "# The following is run in parallel on each host on a GPU cluster or TPU pod slice.\n",
    "import jax\n",
    "# jax.distributed.initialize()  # On GPU, see above for the necessary arguments.\n",
    "jax.device_count()  # total number of accelerator devices in the cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.local_device_count()  # number of accelerator devices attached to this host"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([3., 3., 3.], dtype=float32)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The psum is performed over all mapped devices across the pod slice\n",
    "xs = jax.numpy.ones(jax.local_device_count())\n",
    "jax.pmap(lambda x: jax.lax.psum(x, 'i'), axis_name='i')(xs)\n",
    "# ShardedDeviceArray([32., 32., 32., 32., 32., 32., 32., 32.], dtype=float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "Array([11., 20., 29.], dtype=float32)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.arange(5)\n",
    "w = jnp.array([2., 3., 4.])\n",
    "\n",
    "def convolve(x, w):\n",
    "  output = []\n",
    "  for i in range(1, len(x)-1):\n",
    "    output.append(jnp.dot(x[i-1:i+2], w))\n",
    "  return jnp.array(output)\n",
    "\n",
    "convolve(x, w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2,3'\n",
    "\n",
    "import jax\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "size = 5\n",
    "x = jnp.arange(size)\n",
    "w = jnp.array([2., 3., 4.])\n",
    "\n",
    "\n",
    "def convolve(x, w):\n",
    "  output = []\n",
    "  for i in range(1, len(x)-1):\n",
    "    output.append(jnp.dot(x[i-1:i+2], w))\n",
    "  return jnp.array(output)\n",
    "\n",
    "iter = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5886805057525635\n",
      "[  11.   20.   29.   38.   47.   56.   65.   74.   83.   92.  101.  110.\n",
      "  119.  128.  137.  146.  155.  164.  173.  182.  191.  200.  209.  218.\n",
      "  227.  236.  245.  254.  263.  272.  281.  290.  299.  308.  317.  326.\n",
      "  335.  344.  353.  362.  371.  380.  389.  398.  407.  416.  425.  434.\n",
      "  443.  452.  461.  470.  479.  488.  497.  506.  515.  524.  533.  542.\n",
      "  551.  560.  569.  578.  587.  596.  605.  614.  623.  632.  641.  650.\n",
      "  659.  668.  677.  686.  695.  704.  713.  722.  731.  740.  749.  758.\n",
      "  767.  776.  785.  794.  803.  812.  821.  830.  839.  848.  857.  866.\n",
      "  875.  884.  893.  902.  911.  920.  929.  938.  947.  956.  965.  974.\n",
      "  983.  992. 1001. 1010. 1019. 1028. 1037. 1046. 1055. 1064. 1073. 1082.\n",
      " 1091. 1100. 1109. 1118. 1127. 1136. 1145. 1154. 1163. 1172. 1181. 1190.\n",
      " 1199. 1208. 1217. 1226. 1235. 1244. 1253. 1262. 1271. 1280. 1289. 1298.\n",
      " 1307. 1316. 1325. 1334. 1343. 1352. 1361. 1370. 1379. 1388. 1397. 1406.\n",
      " 1415. 1424. 1433. 1442. 1451. 1460. 1469. 1478. 1487. 1496. 1505. 1514.\n",
      " 1523. 1532. 1541. 1550. 1559. 1568. 1577. 1586. 1595. 1604. 1613. 1622.\n",
      " 1631. 1640. 1649. 1658. 1667. 1676. 1685. 1694. 1703. 1712. 1721. 1730.\n",
      " 1739. 1748. 1757. 1766. 1775. 1784.]\n",
      "0.0011823177337646484\n",
      "[  11.   20.   29.   38.   47.   56.   65.   74.   83.   92.  101.  110.\n",
      "  119.  128.  137.  146.  155.  164.  173.  182.  191.  200.  209.  218.\n",
      "  227.  236.  245.  254.  263.  272.  281.  290.  299.  308.  317.  326.\n",
      "  335.  344.  353.  362.  371.  380.  389.  398.  407.  416.  425.  434.\n",
      "  443.  452.  461.  470.  479.  488.  497.  506.  515.  524.  533.  542.\n",
      "  551.  560.  569.  578.  587.  596.  605.  614.  623.  632.  641.  650.\n",
      "  659.  668.  677.  686.  695.  704.  713.  722.  731.  740.  749.  758.\n",
      "  767.  776.  785.  794.  803.  812.  821.  830.  839.  848.  857.  866.\n",
      "  875.  884.  893.  902.  911.  920.  929.  938.  947.  956.  965.  974.\n",
      "  983.  992. 1001. 1010. 1019. 1028. 1037. 1046. 1055. 1064. 1073. 1082.\n",
      " 1091. 1100. 1109. 1118. 1127. 1136. 1145. 1154. 1163. 1172. 1181. 1190.\n",
      " 1199. 1208. 1217. 1226. 1235. 1244. 1253. 1262. 1271. 1280. 1289. 1298.\n",
      " 1307. 1316. 1325. 1334. 1343. 1352. 1361. 1370. 1379. 1388. 1397. 1406.\n",
      " 1415. 1424. 1433. 1442. 1451. 1460. 1469. 1478. 1487. 1496. 1505. 1514.\n",
      " 1523. 1532. 1541. 1550. 1559. 1568. 1577. 1586. 1595. 1604. 1613. 1622.\n",
      " 1631. 1640. 1649. 1658. 1667. 1676. 1685. 1694. 1703. 1712. 1721. 1730.\n",
      " 1739. 1748. 1757. 1766. 1775. 1784.]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(iter):\n",
    "  t0 = time.time()\n",
    "  a=jax.jit(convolve)(x, w)\n",
    "  print(time.time() - t0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_devices = jax.local_device_count()\n",
    "xs = np.arange(size * n_devices).reshape(-1, size)\n",
    "ws = np.stack([w] * n_devices)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for _ in range(iter):\n",
    "  t0 = time.time()\n",
    "  jax.vmap(convolve)(xs, ws)\n",
    "  print(time.time() - t0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for _ in range(iter):\n",
    "  t0 = time.time()\n",
    "  a = jax.pmap(convolve)(xs, ws).block_until_ready()\n",
    "  print(time.time() - t0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
